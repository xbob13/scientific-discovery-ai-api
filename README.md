# ğŸ§  Scientific Discovery AI â€“ Full System

This repository includes both:

- âœ… A Google Colab-compatible **training script** to fine-tune a language model on 1000+ arXiv papers
- ğŸŒ A **FastAPI inference server** deployable on Render to serve your trained model

---

## ğŸ—ï¸ Structure

```
ğŸ“ scientific-discovery-ai-full/
â”œâ”€â”€ api/                     # Render API backend
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ render.yaml
â”œâ”€â”€ scientific_discovery_ai_training.py  # Colab training pipeline
â””â”€â”€ README.md
```

---

## ğŸ”§ Render API Endpoint

Deploy `api/` to [Render](https://render.com/) and POST to `/generate` with a JSON body:

```json
{ "prompt": "What connects quantum mechanics and biology?" }
```

---

## ğŸ§ª Model Training (Colab)

Use `scientific_discovery_ai_training.py` to:

- Install dependencies
- Collect papers from arXiv
- Build cross-disciplinary dataset
- Fine-tune a model with LoRA
- Save model for Hugging Face or Render

---

## ğŸ“¦ Hugging Face

Publish your trained model to Hugging Face:
```bash
from transformers import AutoModelForCausalLM, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("./scientific-discovery-ai")
model = AutoModelForCausalLM.from_pretrained("./scientific-discovery-ai")

model.push_to_hub("your-username/scientific-discovery-ai")
tokenizer.push_to_hub("your-username/scientific-discovery-ai")
```

---

